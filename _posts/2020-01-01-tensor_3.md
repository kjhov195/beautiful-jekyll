---
layout: post
title: Tensor(3)
subtitle: Deep Learning
category: Deep Learning
use_math: true
---

<br>

우선, 해당 포스트는 [모두를 위한 딥러닝 시즌2](https://deeplearningzerotoall.github.io/season2/lec_pytorch.html)의 자료를 기본으로 하여 정리한 내용임을 밝힙니다.

<br>
<br>
### Type casting
```
### Type casting
lt = torch.LongTensor([1, 2, 3, 4])
print(lt)

print(lt.float())
```

우선 LongTensor lt를 만들어준다. lt.float()라는 간단한 함수를 통하여 LongTensor lt를 FlaotTensor로 변환할 수 있다.

<br>

```
bt = torch.ByteTensor([True, False, False, True])
print(bt)

print(bt.long())
print(bt.float())
```

PyTorch에서 사용하는 Boolean Type의 Tensor는 ByteTensor라고 한다. 이 ByteTensor 또한 .long(), .float()와 같은 함수를 통하여 long, float의 자료형을 가지는 Tensor로 변환시킬 수 있다.

<br>
<br>
### Ones/Zeros
```
### ones, zeros
x = torch.FloatTensor([[0, 1, 2], [2, 1, 0]])
print(x)

print(torch.ones_like(x))
print(torch.zeros_like(x))
```

np.ones(), np.zeros(), np.ones_like(), np.zeros_like()와 거의 비슷한 기능을 하는 함수라고 생각하면 된다.

다만 torch.ones_like()와 torch.zeros_like() device 지정 또한 같게 만들어준다는 점에서 다른 점을 가지고 있다. cpu/gpu tensor, 혹은 multi-gpu를 사용할 경우 몇 번 gpu의 tensor인지 까지도 같게 선언해준다.

<br>
<br>
### One-hot encoding
```
### One-hot encoding
lt = torch.LongTensor([[0], [1], [2], [0]])
print(lt)
lt.shape

one_hot = torch.zeros(4, 3) # batch_size = 4, classes = 3
one_hot

one_hot.scatter_(1, lt, 1)
print(one_hot)
```

torch.zeros와 scatter function을 함께 사용하여 간단하게 위와 같이 one-hot encoding 또한 해줄 수 있다.

<br>
<br>
### In-place Operation

```
### In-place Operation
x = torch.FloatTensor([[1, 2], [3, 4]])

print(x.mul(2.))
print(x)
```

Tensor의 연산 결과를 메모리에 새로 선언하지 않고, 기존의 Tensor에 수정해주고 싶을 때 사용하는 함수이다.

일반적인 multiplication 함수인 .mul()함수를 사용했을 때에는 연산 이후에 x를 살펴보아도 연산 전과 똑같은 결과를 return해 준다.

```
print(x.mul_(2.))
print(x)
```

반면 " _ ", 즉 In-place operation을 사용한  multiplication 함수인 .mul_()를 사용했을 때에는 연산 이후에 x가 연산 결과로 바뀌어 있는 것을 확인할 수 있다.


<br>
<br>
### Reference
[모두를 위한 딥러닝 시즌2](https://deeplearningzerotoall.github.io/season2/lec_pytorch.html)
